{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Michael Muschitiello // Robust Beta Computation\n",
    "\n",
    "\n",
    "This notebook calculates both long-term and short-term betas for a “Magnificent 7” portfolio relative to the S&P 500. \n",
    "It demonstrates a multi-step workflow:\n",
    "\n",
    "1. **Long-Term Beta (Monthly)**  \n",
    "   - Gathers monthly price data (including dividends) for the Magnificent 7 and for the S&P 500.  \n",
    "   - Combines dividend amounts with monthly closing prices, producing “total” monthly prices.  \n",
    "   - Computes monthly log returns, then calculates beta in two ways:  \n",
    "     - **Cov/Var beta** for a quick estimate.  \n",
    "     - **Weighted Least Squares (WLS)** with exponential decay to emphasized recent data while still retaining historical trends.  \n",
    "\n",
    "2. **Short-Term Beta (Weekly)**  \n",
    "   - Gathers weekly price data and dividends from Yahoo Finance starting around mid-2023.  \n",
    "   - Combines dividend amounts with weekly closing prices, then computes weekly log returns.  \n",
    "   - Estimates beta using both Cov/Var and WLS with a decay factor that assigns 50% weight to the earliest observation.  \n",
    "\n",
    "3. **Serial Correlation Testing**  \n",
    "   - Uses Ljung-Box tests for both daily and weekly returns across specified date ranges (2019–2025 and 12/2023–2025).  \n",
    "   - Prints results indicating whether any ticker exhibits statistically significant autocorrelation.\n",
    "\n",
    "4. **Interpretation & Diagnostics**  \n",
    "   - Prints regression summaries (alpha, beta, R-squared, residual standard deviation).  \n",
    "   - Decomposes the relative contribution of the Magnificent 7 portion (roughly 28.38% of S&P 500) versus the other ~493 stocks.\n",
    "\n",
    "## Use Cases\n",
    "- **Portfolio Construction**: Helps shape a “beta-neutral” or “factor-based” strategy using estimated betas.  \n",
    "- **Risk & Attribution**: Assesses how much risk Magnificent 7 adds to the S&P 500.  \n",
    "- **Statistic Checks**: Quickly identifies presence or absence of serial correlation in returns.  \n",
    "\n",
    "Overall, this notebook provides a comprehensive blueprint for integrating monthly and weekly price data, dividends, and WLS regression to estimate an evolving beta for a subset of the S&P 500 under varying time horizons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long-term Beta calculation:\n",
    "- Monthly total log returns\n",
    "- WLS Regression\n",
    "- Exponential decay factor lambda = 0.9832 to give .35 weight to oldest observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import yfinance as yf \n",
    "import matplotlib.pyplot as plt \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing for serial correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  8 of 8 completed\n",
      "[*********************100%***********************]  8 of 8 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DAILY (2019–2025) ===\n",
      "AAPL: Serial Correlation? YES (p=2.437e-12)\n",
      "AMZN: Serial Correlation? NO (p=3.190e-01)\n",
      "GOOGL: Serial Correlation? YES (p=8.902e-08)\n",
      "META: Serial Correlation? YES (p=4.436e-02)\n",
      "MSFT: Serial Correlation? YES (p=3.442e-25)\n",
      "NVDA: Serial Correlation? YES (p=7.889e-06)\n",
      "SPY: Serial Correlation? YES (p=9.441e-43)\n",
      "TSLA: Serial Correlation? NO (p=7.759e-02)\n",
      "\n",
      "=== DAILY (12/2023–2025) ===\n",
      "AAPL: Serial Correlation? NO (p=6.898e-01)\n",
      "AMZN: Serial Correlation? NO (p=4.132e-01)\n",
      "GOOGL: Serial Correlation? NO (p=6.730e-01)\n",
      "META: Serial Correlation? NO (p=5.958e-01)\n",
      "MSFT: Serial Correlation? NO (p=4.932e-01)\n",
      "NVDA: Serial Correlation? NO (p=4.380e-01)\n",
      "SPY: Serial Correlation? NO (p=7.303e-01)\n",
      "TSLA: Serial Correlation? NO (p=7.592e-01)\n",
      "\n",
      "=== WEEKLY (2019–2025) ===\n",
      "AAPL: Serial Correlation? NO (p=6.599e-01)\n",
      "AMZN: Serial Correlation? NO (p=1.165e-01)\n",
      "GOOGL: Serial Correlation? NO (p=2.221e-01)\n",
      "META: Serial Correlation? NO (p=6.769e-01)\n",
      "MSFT: Serial Correlation? NO (p=4.123e-01)\n",
      "NVDA: Serial Correlation? NO (p=4.489e-01)\n",
      "SPY: Serial Correlation? NO (p=6.440e-01)\n",
      "TSLA: Serial Correlation? NO (p=3.264e-01)\n",
      "\n",
      "=== WEEKLY (12/2023–2025) ===\n",
      "AAPL: Serial Correlation? NO (p=4.213e-01)\n",
      "AMZN: Serial Correlation? NO (p=6.134e-01)\n",
      "GOOGL: Serial Correlation? NO (p=6.533e-01)\n",
      "META: Serial Correlation? NO (p=8.880e-01)\n",
      "MSFT: Serial Correlation? NO (p=5.168e-01)\n",
      "NVDA: Serial Correlation? NO (p=6.561e-01)\n",
      "SPY: Serial Correlation? NO (p=1.494e-01)\n",
      "TSLA: Serial Correlation? NO (p=8.503e-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def ljung_box_test(returns, max_lag=20):\n",
    "    \"\"\"\n",
    "    Runs Ljung-Box test for serial correlation up to 'max_lag'.\n",
    "    Returns a string indicating whether p-value < 0.05 (i.e., significant serial correlation).\n",
    "    \"\"\"\n",
    "    # You can test multiple lags, but here we just take the p-value from the highest lag\n",
    "    result = acorr_ljungbox(returns.dropna(), lags=[max_lag], return_df=True)\n",
    "    p_value = result['lb_pvalue'].iloc[-1]\n",
    "    if p_value < 0.05:\n",
    "        return f\"YES (p={p_value:.3e})\"\n",
    "    else:\n",
    "        return f\"NO (p={p_value:.3e})\"\n",
    "\n",
    "# 1) Define your tickers and date ranges\n",
    "tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'NVDA', 'TSLA', 'SPY']\n",
    "start_long, end_long = '2019-01-01', '2025-12-31'\n",
    "start_short, end_short = '2023-12-01', '2025-12-31'\n",
    "\n",
    "# 2) Download daily price data for both time windows\n",
    "data_long = yf.download(tickers, start=start_long, end=end_long, auto_adjust=True)['Close']\n",
    "data_short = yf.download(tickers, start=start_short, end=end_short, auto_adjust=True)['Close']\n",
    "\n",
    "# 3) Compute daily log returns\n",
    "daily_returns_long = np.log(data_long / data_long.shift(1)).dropna()\n",
    "daily_returns_short = np.log(data_short / data_short.shift(1)).dropna()\n",
    "\n",
    "# 4) Compute weekly log returns (resample last business day of each week)\n",
    "weekly_prices_long = data_long.resample('W-FRI').last().dropna()\n",
    "weekly_returns_long = np.log(weekly_prices_long / weekly_prices_long.shift(1)).dropna()\n",
    "\n",
    "weekly_prices_short = data_short.resample('W-FRI').last().dropna()\n",
    "weekly_returns_short = np.log(weekly_prices_short / weekly_prices_short.shift(1)).dropna()\n",
    "\n",
    "# 5) Run Ljung-Box test for each ticker in each set\n",
    "def print_serial_corr_results(name, df_returns, max_lag=10):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    for col in df_returns.columns:\n",
    "        test_result = ljung_box_test(df_returns[col], max_lag)\n",
    "        print(f\"{col}: Serial Correlation? {test_result}\")\n",
    "\n",
    "# Daily (2019–2025)\n",
    "print_serial_corr_results(\"DAILY (2019–2025)\", daily_returns_long)\n",
    "\n",
    "# Daily (12/2023–2025)\n",
    "print_serial_corr_results(\"DAILY (12/2023–2025)\", daily_returns_short)\n",
    "\n",
    "# Weekly (2019–2025)\n",
    "print_serial_corr_results(\"WEEKLY (2019–2025)\", weekly_returns_long)\n",
    "\n",
    "# Weekly (12/2023–2025)\n",
    "print_serial_corr_results(\"WEEKLY (12/2023–2025)\", weekly_returns_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Beta (Cov/Var) for Magnificent 7: 1.274\n",
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.641\n",
      "Model:                            WLS   Adj. R-squared:                  0.635\n",
      "Method:                 Least Squares   F-statistic:                     107.1\n",
      "Date:                Fri, 28 Feb 2025   Prob (F-statistic):           5.71e-15\n",
      "Time:                        12:17:09   Log-Likelihood:                 100.92\n",
      "No. Observations:                  62   AIC:                            -197.8\n",
      "Df Residuals:                      60   BIC:                            -193.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0098      0.006      1.595      0.116      -0.002       0.022\n",
      "^SPX           1.2865      0.124     10.351      0.000       1.038       1.535\n",
      "==============================================================================\n",
      "Omnibus:                        1.251   Durbin-Watson:                   1.713\n",
      "Prob(Omnibus):                  0.535   Jarque-Bera (JB):                0.640\n",
      "Skew:                           0.196   Prob(JB):                        0.726\n",
      "Kurtosis:                       3.306   Cond. No.                         20.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "5Y Monthly Returns Weighted Least Squares Results:\n",
      "Estimated alpha: 0.009772\n",
      "Estimated beta:  1.286540\n",
      "R-squared:       0.641008\n",
      "Residual Std:    0.048557\n",
      "\n",
      "Beta of the ~493 other stocks: 0.886458\n",
      "Percent contribution of Magnificent 7: 0.365116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\musch\\AppData\\Local\\Temp\\ipykernel_38720\\2736430384.py:109: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_est = results.params[0]\n",
      "C:\\Users\\musch\\AppData\\Local\\Temp\\ipykernel_38720\\2736430384.py:110: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  beta_est  = results.params[1]\n"
     ]
    }
   ],
   "source": [
    "start = '2019-12-01'\n",
    "end   = '2025-02-17'\n",
    "mag7  = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'NVDA', 'TSLA', '^SPX']\n",
    "\n",
    "# read in weight data for Magnificent 7 (as of 1/31/25)\n",
    "weight_data = pd.read_excel(\"S&P 500 1-31-25.xlsx\", sheet_name=\"20250131_SP500_CLS\")\n",
    "weight_data = weight_data[['BLOOMBERG TICKER', 'INDEX MARKET CAP']].iloc[:7].copy()\n",
    "total_mkcap_mag7 = weight_data['INDEX MARKET CAP'].sum()\n",
    "weight_data['Weight in Mag7 Portfolio'] = weight_data['INDEX MARKET CAP'] / total_mkcap_mag7\n",
    "weight_data['BLOOMBERG TICKER'] = weight_data['BLOOMBERG TICKER'].str.replace(' UQ', '', regex=False)\n",
    "\n",
    "# download daily data for dividends\n",
    "price_data      = {}\n",
    "dividend_events = []\n",
    "\n",
    "for ticker in mag7:\n",
    "    hist = yf.Ticker(ticker).history(start=start, end=end)\n",
    "    price_data[ticker] = hist\n",
    "    divs = hist['Dividends'][hist['Dividends'] > 0]\n",
    "    \n",
    "    for date, dividend in divs.items():\n",
    "        try:\n",
    "            date_idx = hist.index.get_loc(date)\n",
    "            # skip if no prior day\n",
    "            if date_idx == 0:\n",
    "                continue\n",
    "            prev_date = hist.index[date_idx - 1]\n",
    "            S         = hist.loc[prev_date, 'Close']\n",
    "            dividend_events.append({\n",
    "                'Ticker': ticker,\n",
    "                'DividendDate': pd.to_datetime(date),\n",
    "                'Dividend': dividend,\n",
    "                'PriceBefore': S\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ticker} on {date}: {e}\")\n",
    "\n",
    "df_div = pd.DataFrame(dividend_events).sort_values('DividendDate')\n",
    "# convert index to date only, ignoring time\n",
    "df_div['DividendDate'] = pd.to_datetime(df_div['DividendDate']).dt.date\n",
    "df_div.set_index('DividendDate', inplace=True)\n",
    "\n",
    "# convert dividends to monthly period, pivot, shift\n",
    "df_div.index = pd.to_datetime(df_div.index)\n",
    "df_div['Month'] = df_div.index.to_period('M')\n",
    "\n",
    "dividends_pivot = (\n",
    "    df_div\n",
    "    .groupby(['Month','Ticker'])['Dividend']\n",
    "    .sum()\n",
    "    .unstack('Ticker')\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# shift dividends so that dividends in Feb are added to the March price\n",
    "dividends_pivot.index = dividends_pivot.index + 1\n",
    "\n",
    "# download monthly closing prices for the same tickers\n",
    "monthly_prices = pd.DataFrame()\n",
    "for ticker in mag7:\n",
    "    data = yf.download(ticker, start=start, end=end, interval='1mo')['Close']\n",
    "    data.name = ticker\n",
    "    monthly_prices = pd.concat([monthly_prices, data], axis=1)\n",
    "\n",
    "# move index to column and set a monthly PeriodIndex\n",
    "monthly_prices.reset_index(inplace=True)\n",
    "monthly_prices['Month'] = monthly_prices['Date'].dt.to_period('M')\n",
    "monthly_prices.set_index('Month', inplace=True)\n",
    "\n",
    "# align columns with pivoted dividends and add them\n",
    "common_div, common_prices = dividends_pivot.align(\n",
    "    monthly_prices.drop(columns=['Date'], errors='ignore'),\n",
    "    axis=1, join='outer', fill_value=0\n",
    ")\n",
    "adjusted_prices = common_prices.add(common_div, fill_value=0)\n",
    "\n",
    "# drop final row if it extends beyond the dividend data\n",
    "adjusted_prices = adjusted_prices.iloc[:-1]\n",
    "\n",
    "# compute monthly log returns\n",
    "log_returns = np.log(adjusted_prices / adjusted_prices.shift(1)).dropna()\n",
    "\n",
    "# build the cap-weighted portfolio returns for Magnificent 7\n",
    "mag7_only     = ['AAPL','MSFT','NVDA','AMZN','META','GOOGL','TSLA']\n",
    "mag7_port_wt  = weight_data['Weight in Mag7 Portfolio'].values  # ordering must match mag7_only\n",
    "mag7_log_rets = log_returns[mag7_only].values\n",
    "weighted_mag7_rets = mag7_log_rets @ mag7_port_wt\n",
    "\n",
    "# pull SPX log returns\n",
    "spx_monthly_logrets = log_returns['^SPX']\n",
    "\n",
    "# basic Beta Calculation via Cov/Var\n",
    "beta_mag7 = np.cov(weighted_mag7_rets, spx_monthly_logrets)[0, 1] / np.var(spx_monthly_logrets)\n",
    "print(f\"Simple Beta (Cov/Var) for Magnificent 7: {beta_mag7:.3f}\")\n",
    "\n",
    "# weighted Least Squares (exponential weighting)\n",
    "X = sm.add_constant(spx_monthly_logrets)\n",
    "y = weighted_mag7_rets\n",
    "\n",
    "T = len(y)\n",
    "lmbda = 0.9832  # decay\n",
    "weights = np.array([lmbda**(T-1-i) for i in range(T)], dtype=float)\n",
    "\n",
    "model   = sm.WLS(y, X, weights=weights)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "alpha_est = results.params[0]\n",
    "beta_est  = results.params[1]\n",
    "print(\"\\n5Y Monthly Returns Weighted Least Squares Results:\")\n",
    "print(f\"Estimated alpha: {alpha_est:.6f}\")\n",
    "print(f\"Estimated beta:  {beta_est:.6f}\")\n",
    "print(f\"R-squared:       {results.rsquared:.6f}\")\n",
    "print(f\"Residual Std:    {results.resid.std():.6f}\")\n",
    "\n",
    "# beta of the other ~493 stocks & contribution\n",
    "mag7_sp_weight = 0.2837966\n",
    "beta_493 = (1.0 - mag7_sp_weight*beta_est) / (1.0 - mag7_sp_weight)\n",
    "print(f\"\\nBeta of the ~493 other stocks: {beta_493:.6f}\")\n",
    "print(f\"Percent contribution of Magnificent 7: {mag7_sp_weight * beta_est:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Term Beta(18m)\n",
    "- Weekly total log returns\n",
    "- WLS regression\n",
    "- exponential decay rate lambda = .9966571 giving .5 weight to the oldest obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Cov/Var Beta for Mag7 weekly returns: 1.446791\n",
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.700\n",
      "Model:                            WLS   Adj. R-squared:                  0.696\n",
      "Method:                 Least Squares   F-statistic:                     177.6\n",
      "Date:                Fri, 28 Feb 2025   Prob (F-statistic):           1.40e-21\n",
      "Time:                        12:17:21   Log-Likelihood:                 210.09\n",
      "No. Observations:                  78   AIC:                            -416.2\n",
      "Df Residuals:                      76   BIC:                            -411.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0012      0.002      0.644      0.521      -0.003       0.005\n",
      "^SPX           1.4237      0.107     13.328      0.000       1.211       1.636\n",
      "==============================================================================\n",
      "Omnibus:                        1.107   Durbin-Watson:                   2.049\n",
      "Prob(Omnibus):                  0.575   Jarque-Bera (JB):                1.179\n",
      "Skew:                           0.224   Prob(JB):                        0.555\n",
      "Kurtosis:                       2.597   Cond. No.                         57.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "18M Weekly Returns Weighted Least Squares Results:\n",
      "Estimated alpha: 0.001244\n",
      "Estimated beta:  1.423696\n",
      "R-squared:       0.700351\n",
      "Residual Std:    0.016434\n",
      "\n",
      "The Beta of the ~493 other stocks in the SP500 is: 0.832110\n",
      "The percentage of SPX beta contributed by the Magnificent 7 is: 0.404040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tickers, date range, weight data\n",
    "start = '2023-8-17'\n",
    "end   = '2025-02-17'\n",
    "mag7  = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'NVDA', 'TSLA', '^SPX']\n",
    "\n",
    "# download weekly prices & identify dividend events\n",
    "price_data      = {}\n",
    "dividend_events = []\n",
    "\n",
    "for ticker in mag7:\n",
    "    stock = yf.Ticker(ticker)\n",
    "    hist  = stock.history(start=start, end=end)  # daily data for dividends\n",
    "    price_data[ticker] = hist\n",
    "    divs  = hist['Dividends'][hist['Dividends'] > 0]\n",
    "\n",
    "    for dt, dividend in divs.items():\n",
    "        idx = hist.index.get_loc(dt)\n",
    "        if idx > 0:\n",
    "            prev_date   = hist.index[idx - 1]\n",
    "            price_close = hist.loc[prev_date, 'Close']\n",
    "            dividend_events.append({\n",
    "                'Ticker': ticker,\n",
    "                'DividendDate': pd.to_datetime(dt),\n",
    "                'Dividend':     dividend,\n",
    "                'PriceBefore':  price_close\n",
    "            })\n",
    "\n",
    "df_div = pd.DataFrame(dividend_events).sort_values('DividendDate')\n",
    "df_div['DividendDate'] = pd.to_datetime(df_div['DividendDate']).dt.date\n",
    "df_div.set_index('DividendDate', inplace=True)\n",
    "\n",
    "# 3. Convert dividends to weekly frequency & sum by ticker\n",
    "df_div.index = pd.to_datetime(df_div.index)\n",
    "df_div['Week'] = df_div.index.to_period('W-SUN')\n",
    "dividends_weekly = df_div.groupby(['Week','Ticker'])['Dividend'].sum().unstack('Ticker').fillna(0)\n",
    "\n",
    "# 4. Download weekly close prices for Mag7 + SPX\n",
    "weekly_prices = pd.DataFrame()\n",
    "for ticker in mag7:\n",
    "    data      = yf.download(ticker, start=start, end=end, interval='1wk', auto_adjust=False)['Close']\n",
    "    data.name = ticker\n",
    "    weekly_prices = pd.concat([weekly_prices, data], axis=1)\n",
    "\n",
    "# Convert index to weekly PeriodIndex\n",
    "weekly_prices.index = pd.to_datetime(weekly_prices.index)\n",
    "weekly_prices['Week'] = weekly_prices.index.to_period('W-SUN')\n",
    "weekly_prices.set_index('Week', inplace=True)\n",
    "\n",
    "# 5. Add weekly dividends to the weekly closing prices\n",
    "aligned_div, aligned_prices = dividends_weekly.align(\n",
    "    weekly_prices.drop(columns=['Date'], errors='ignore'),\n",
    "    join='outer', axis=1, fill_value=0\n",
    ")\n",
    "adjusted_weekly_prices = aligned_prices.add(aligned_div, fill_value=0)\n",
    "adjusted_weekly_prices.index = adjusted_weekly_prices.index.to_timestamp()\n",
    "\n",
    "# 6. Calculate weekly log returns (drop the first row of NaNs)\n",
    "weekly_log_rets = np.log(adjusted_weekly_prices / adjusted_weekly_prices.shift(1)).dropna()\n",
    "\n",
    "# build the cap-weighted Mag7 portfolio returns\n",
    "mag7_only        = ['AAPL', 'MSFT', 'NVDA', 'AMZN', 'META', 'GOOGL', 'TSLA']\n",
    "mag7_port_weights = weight_data['Weight in Mag7 Portfolio'].values\n",
    "mag7_log_rets = weekly_log_rets[mag7_only].values\n",
    "weighted_mag7_rets = mag7_log_rets @ mag7_port_weights\n",
    "\n",
    "# SPX returns\n",
    "spx_weekly_logrets = weekly_log_rets['^SPX']\n",
    "\n",
    "# simple Beta Calculation (Cov/Var)\n",
    "beta_mag7 = np.cov(weighted_mag7_rets, spx_weekly_logrets)[0,1] / np.var(spx_weekly_logrets)\n",
    "print(f\"Simple Cov/Var Beta for Mag7 weekly returns: {beta_mag7:.6f}\")\n",
    "\n",
    "\n",
    "# Weighted Least Squares Beta (Exponential Weighting)\n",
    "X = sm.add_constant(spx_weekly_logrets)\n",
    "y = weighted_mag7_rets\n",
    "T = len(y)\n",
    "lmbda = .9966571 # giving 50% weight to the oldest obs \n",
    "\n",
    "weights = np.array([lmbda**(T-1 - i) for i in range(T)], dtype=float)\n",
    "model = sm.WLS(y, X, weights=weights)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "alpha_est = results.params.iloc[0]\n",
    "beta_est  = results.params.iloc[1]\n",
    "print(\"\\n18M Weekly Returns Weighted Least Squares Results:\")\n",
    "print(f\"Estimated alpha: {alpha_est:.6f}\")\n",
    "print(f\"Estimated beta:  {beta_est:.6f}\")\n",
    "print(f\"R-squared:       {results.rsquared:.6f}\")\n",
    "print(f\"Residual Std:    {results.resid.std():.6f}\")\n",
    "\n",
    "\n",
    "# beta of Other ~493 Stocks + Magnificent 7 Contribution\n",
    "mag7_sp_weight = 0.2837966\n",
    "beta_493 = (1.0 - mag7_sp_weight * beta_est) / (1.0 - mag7_sp_weight)\n",
    "contrib   = mag7_sp_weight * beta_est\n",
    "\n",
    "print(f\"\\nThe Beta of the ~493 other stocks in the SP500 is: {beta_493:.6f}\")\n",
    "print(f\"The percentage of SPX beta contributed by the Magnificent 7 is: {contrib:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
